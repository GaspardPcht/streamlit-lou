import streamlit as st
import pandas as pd
import csv
import chardet
from io import StringIO, BytesIO
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# Import optionnel de reportlab (PDF)
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib import colors
    HAS_REPORTLAB = True
except Exception:
    HAS_REPORTLAB = False

st.set_page_config(page_title="üìä Analyseur Marketing", layout="wide")

# CSS pour am√©liorer le rendu
st.markdown("""
<style>
    .main-header {font-size: 2.5rem; font-weight: bold; color: #1f77b4;}
    .metric-card {background-color: #f0f2f6; padding: 1rem; border-radius: 0.5rem;}
</style>
""", unsafe_allow_html=True)

st.markdown('<p class="main-header">üìä Analyseur de Donn√©es Marketing</p>', unsafe_allow_html=True)
st.write("**Importez vos fichiers CSV/XLS/XLSX ‚Äî Visualisez instantan√©ment vos donn√©es**")

# ========================================
# SECTION 1 : IMPORT MULTI-FICHIERS
# ========================================

st.sidebar.title("üìÅ Import de fichiers")
uploaded_files = st.sidebar.file_uploader(
    "Glissez vos fichiers ici (CSV, XLSX ou XLS)",
    type=["csv", "xlsx", "xls"],
    accept_multiple_files=True,
    help="Vous pouvez importer plusieurs fichiers en m√™me temps"
)

@st.cache_data
def load_single_file(file_content, file_name):
    """Charge un fichier CSV/Excel de mani√®re robuste.
    - G√®re 'sep=,' en premi√®re ligne.
    - Ignore les lignes de titre/metadata avant l‚Äôen-t√™te (ex: "Vues").
    - Supporte plusieurs tableaux dans un m√™me CSV (s√©par√©s par lignes vides) et les concat√®ne.
    - Supporte aussi plusieurs tableaux cons√©cutifs sans ligne vide via d√©tection d'un nouvel en-t√™te.
    - Supporte les formats Excel .xls et .xlsx en essayant plusieurs engines si n√©cessaire.
    """
    try:
        lower_name = file_name.lower()
        if lower_name.endswith('.csv'):
            # D√©tection encodage et normalisation des fins de ligne
            result = chardet.detect(file_content)
            encoding = result.get('encoding') or 'utf-8'
            text = file_content.decode(encoding, errors='ignore').replace('\r\n', '\n').replace('\r', '\n')
            lines = text.split('\n')

            # 1) D√©tecter 'sep=' et le sauter
            sep = None
            start_idx = 0
            if lines and lines[0].strip().lower().startswith('sep='):
                cand = lines[0].split('=', 1)[1].strip()
                sep = cand[0] if cand else ','
                start_idx = 1

            # 2) D√©tecter le s√©parateur si non fix√©
            if sep is None:
                sample = '\n'.join(lines[:50])
                try:
                    sep = csv.Sniffer().sniff(sample).delimiter
                except Exception:
                    sep = ',' if sample.count(',') >= sample.count(';') else ';'

            # 3) Trouver la vraie ligne d'en-t√™te (ignore titres/metadata comme "Vues")
            header_idx = start_idx
            for i in range(start_idx, min(len(lines), 200)):
                raw = lines[i].lstrip('\ufeff').strip()
                if not raw or raw.lower().startswith('sep='):
                    continue
                # en-t√™te plausible si contient au moins un s√©parateur
                if sep in raw and raw.count(sep) >= 1:
                    header_idx = i
                    break

            # 4) Contenu utile
            clean_text = '\n'.join(lines[header_idx:]).lstrip('\ufeff').strip()

            # 5) Essayer de lire plusieurs blocs (plusieurs tableaux s√©par√©s par lignes vides)
            blocks = [b.strip() for b in clean_text.split('\n\n') if b.strip()]
            frames = []
            table_counter = 0
            for b in blocks:
                # D√©tection d'en-t√™tes internes (cas de tableaux cons√©cutifs sans lignes vides)
                sub_lines_all = [ln for ln in b.split('\n') if ln is not None]
                # Enlever ent√™tes/billets vides en d√©but
                sub_lines = [ln for ln in sub_lines_all if ln.strip() != '']
                if not sub_lines:
                    continue
                base_header = sub_lines[0].strip()

                # Trouver positions d'en-t√™te candidates
                header_positions = []
                for j, ln in enumerate(sub_lines):
                    s = ln.strip()
                    if not s:
                        continue
                    if s == base_header:
                        header_positions.append(j)
                        continue
                    if sep in s:
                        fields = [x.strip().strip('"') for x in s.split(sep)]
                        if len(fields) >= 1:
                            non_digit_text = 0
                            for f in fields:
                                f2 = f.replace('\xa0', '').strip()
                                has_alpha = any(ch.isalpha() for ch in f2)
                                has_digit = any(ch.isdigit() for ch in f2)
                                # On consid√®re un champ "type ent√™te" s'il a des lettres et aucun chiffre
                                if has_alpha and not has_digit:
                                    non_digit_text += 1
                            # Heuristique stricte: au moins la moiti√© des champs ressemblent √† des labels d'ent√™te
                            if non_digit_text >= max(1, len(fields)//2):
                                header_positions.append(j)

                header_positions = sorted(set(header_positions))

                if len(header_positions) > 1:
                    for s_idx, start in enumerate(header_positions):
                        end = header_positions[s_idx + 1] if s_idx + 1 < len(header_positions) else len(sub_lines)
                        seg = '\n'.join(sub_lines[start:end]).strip()
                        if not seg:
                            continue
                        try:
                            df_block = pd.read_csv(
                                StringIO(seg),
                                sep=sep,
                                engine='python',
                                on_bad_lines='skip'
                            )
                            if df_block.shape[0] > 0 and df_block.shape[1] >= 1:
                                table_counter += 1
                                df_block['_table_id'] = table_counter
                                frames.append(df_block)
                        except Exception:
                            continue
                else:
                    # Aucun second en-t√™te d√©tect√©: lecture simple du bloc
                    try:
                        df_block = pd.read_csv(
                            StringIO(b),
                            sep=sep,
                            engine='python',
                            on_bad_lines='skip'
                        )
                        if df_block.shape[0] > 0 and df_block.shape[1] >= 1:
                            table_counter += 1
                            df_block['_table_id'] = table_counter
                            frames.append(df_block)
                    except Exception:
                        continue

            if frames:
                df_out = pd.concat(frames, ignore_index=True, sort=False)
            else:
                # Fallback: un seul tableau
                df_out = pd.read_csv(
                    StringIO(clean_text),
                    sep=sep,
                    engine='python',
                    on_bad_lines='skip'
                )

            # Nettoyage l√©ger des noms de colonnes
            df_out.columns = [str(c).strip() for c in df_out.columns]
            return df_out

        # Excel (.xls / .xlsx)
        # Lire toutes les feuilles si possible puis concat√©ner pour robustesse
        def _concat_sheets(x):
            frames = []
            if isinstance(x, dict):
                for sheet, df_sheet in x.items():
                    if isinstance(df_sheet, pd.DataFrame) and not df_sheet.empty:
                        df_sheet = df_sheet.copy()
                        df_sheet['_sheet_name'] = str(sheet)
                        frames.append(df_sheet)
            elif isinstance(x, pd.DataFrame):
                return x
            if frames:
                return pd.concat(frames, ignore_index=True, sort=False)
            return None

        try:
            excel_obj = pd.read_excel(BytesIO(file_content), sheet_name=None)
            df_exc = _concat_sheets(excel_obj)
            if df_exc is not None:
                return df_exc
            # fallback si concat a √©chou√©
            if isinstance(excel_obj, dict):
                first = next(iter(excel_obj.values()))
                return first
            return excel_obj
        except Exception:
            # Tentatives cibl√©es par engine
            if lower_name.endswith('.xls'):
                try:
                    excel_obj = pd.read_excel(BytesIO(file_content), engine='xlrd', sheet_name=None)
                    df_exc = _concat_sheets(excel_obj)
                    if df_exc is not None:
                        return df_exc
                    if isinstance(excel_obj, dict):
                        return next(iter(excel_obj.values()))
                    return excel_obj
                except Exception as e:
                    st.error(f"‚ùå Impossible de lire le fichier Excel (.xls) : {file_name}. Installez 'xlrd' (pip install xlrd). Erreur: {e}")
                    return None
            else:
                try:
                    excel_obj = pd.read_excel(BytesIO(file_content), engine='openpyxl', sheet_name=None)
                    df_exc = _concat_sheets(excel_obj)
                    if df_exc is not None:
                        return df_exc
                    if isinstance(excel_obj, dict):
                        return next(iter(excel_obj.values()))
                    return excel_obj
                except Exception as e:
                    st.error(f"‚ùå Impossible de lire le fichier Excel : {file_name}. Erreur: {e}")
                    return None

    except Exception as e:
        st.error(f"‚ùå Erreur {file_name}: {str(e)}")
        return None

# Chargement et fusion des fichiers
df = None
if uploaded_files:
    with st.spinner('‚è≥ Chargement des fichiers...'):
        dfs = []
        for uploaded_file in uploaded_files:
            file_content = uploaded_file.read()
            loaded_df = load_single_file(file_content, uploaded_file.name)
            if loaded_df is not None:
                loaded_df['_fichier_source'] = uploaded_file.name
                dfs.append(loaded_df)

        if dfs:
            df = pd.concat(dfs, ignore_index=True, sort=False)
            st.sidebar.success(f"‚úÖ {len(dfs)} fichier(s) charg√©(s) ‚Äî {len(df):,} lignes au total")
        else:
            st.sidebar.error("‚ùå Aucun fichier valide")

# ========================================
# SECTION 2 : TRAITEMENT DES DONN√âES
# ========================================

def detect_column_types(df):
    """D√©tecte et convertit automatiquement les types de colonnes."""
    df = df.copy()

    # Conversion automatique des dates
    for col in df.columns:
        if col == '_fichier_source':
            continue
        if df[col].dtype == 'object':
            try:
                converted = pd.to_datetime(df[col], errors='coerce')
                if converted.notna().sum() / len(df) > 0.5:
                    df[col] = converted
            except:
                pass

    # Conversion automatique des nombres (m√™me s'ils sont stock√©s comme texte)
    for col in df.columns:
        if col == '_fichier_source':
            continue
        # Si la colonne est d√©j√† num√©rique, on passe
        if pd.api.types.is_numeric_dtype(df[col]):
            continue
        # Si c'est une date, on passe aussi
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            continue
        # Essayer de convertir en num√©rique
        if df[col].dtype == 'object':
            try:
                # Nettoyer TOUS les caract√®res non num√©riques courants
                test_series = df[col].dropna().astype(str).head(100)
                cleaned = (
                    df[col]
                    .astype(str)
                    .str.strip()
                    .str.replace('\xa0', '', regex=False)  # Espace ins√©cable
                    .str.replace(' ', '', regex=False)
                    .str.replace(',', '.', regex=False)   # Virgule d√©cimale
                    .str.replace('‚Ç¨', '', regex=False)
                    .str.replace('$', '', regex=False)
                    .str.replace('¬£', '', regex=False)
                    .str.replace('%', '', regex=False)
                    .str.replace('‚àí', '-', regex=False)   # Signe moins sp√©cial
                    .str.replace('+', '', regex=False)
                )
                converted = pd.to_numeric(cleaned, errors='coerce')
                # Si au moins 50% des valeurs sont des nombres, on convertit
                valid_ratio = converted.notna().sum() / len(df)
                if valid_ratio >= 0.5:
                    df[col] = converted
            except:
                pass

    # Classification des colonnes
    numeric_cols = [c for c in df.columns if c != '_fichier_source' and pd.api.types.is_numeric_dtype(df[c])]
    date_cols = [c for c in df.columns if c != '_fichier_source' and pd.api.types.is_datetime64_any_dtype(df[c])]
    text_cols = [c for c in df.columns if c != '_fichier_source' and c not in numeric_cols and c not in date_cols]

    return df, numeric_cols, date_cols, text_cols


def add_derived_features(df, numeric_cols, date_cols, text_cols):
    """
    Ajoute des colonnes d√©riv√©es pour que toutes les visualisations puissent fonctionner
    m√™me avec un CSV minimal (Date + valeur num√©rique).
    - √Ä partir de la premi√®re colonne de date: Ann√©e, Mois, JourSemaine, SemaineISO.
    - Si une seule colonne num√©rique: ajoute cumul et moyenne mobile 7j.
    """
    df = df.copy()
    new_text = []
    new_num = []

    if date_cols:
        d = date_cols[0]
        try:
            df[d] = pd.to_datetime(df[d], errors='coerce')
        except Exception:
            pass

        # D√©riv√©es cat√©gorielles
        if 'Mois' not in df.columns:
            df['Mois'] = df[d].dt.to_period('M').astype(str)
            new_text.append('Mois')
        if 'Ann√©e' not in df.columns:
            df['Ann√©e'] = df[d].dt.year.astype('Int64')
            df['Ann√©e'] = df['Ann√©e'].astype('string')
            new_text.append('Ann√©e')
        if 'JourSemaine' not in df.columns:
            jours_fr = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']
            df['JourSemaine'] = df[d].dt.weekday.map(lambda i: jours_fr[int(i)] if pd.notna(i) else None)
            new_text.append('JourSemaine')
        if 'SemaineISO' not in df.columns:
            try:
                iso = df[d].dt.isocalendar()
                df['SemaineISO'] = (df[d].dt.year.astype('Int64').astype('string')
                                    + '-W' + iso.week.astype('Int64').astype('string'))
                new_text.append('SemaineISO')
            except Exception:
                pass

    # Num√©riques d√©riv√©es pour d√©bloquer le scatter si besoin
    if len(numeric_cols) == 1:
        n = numeric_cols[0]
        if date_cols:
            df = df.sort_values(by=date_cols[0], kind='stable')
        cum_name = f'{n}_cumule'
        roll_name = f'{n}_rolling7'
        if cum_name not in df.columns:
            try:
                df[cum_name] = df[n].cumsum()
                new_num.append(cum_name)
            except Exception:
                pass
        if roll_name not in df.columns:
            try:
                df[roll_name] = df[n].rolling(window=7, min_periods=1).mean()
                new_num.append(roll_name)
            except Exception:
                pass

    # Mettre √† jour les listes de colonnes
    text_cols = text_cols + [c for c in new_text if c not in text_cols]
    numeric_cols = numeric_cols + [c for c in new_num if c not in numeric_cols]

    return df, numeric_cols, date_cols, text_cols

# ========================================
# SECTION 3 : FILTRES SIMPLES
# ========================================

def apply_filters(df, numeric_cols, date_cols, text_cols):
    """Applique des filtres simples et intuitifs."""
    df_filtered = df.copy()

    with st.sidebar.expander("üîç Filtres", expanded=False):
        # Filtre par date
        if date_cols:
            date_col = st.selectbox("üìÖ Filtrer par date", ["Aucun"] + date_cols)
            if date_col != "Aucun":
                min_date = df[date_col].min()
                max_date = df[date_col].max()
                if pd.notna(min_date) and pd.notna(max_date):
                    date_range = st.date_input(
                        "S√©lectionnez la p√©riode",
                        value=[min_date, max_date],
                        min_value=min_date,
                        max_value=max_date
                    )
                    if len(date_range) == 2:
                        df_filtered = df_filtered[
                            (df_filtered[date_col] >= pd.Timestamp(date_range[0])) &
                            (df_filtered[date_col] <= pd.Timestamp(date_range[1]))
                        ]

        # Filtre par cat√©gorie
        if text_cols:
            text_col = st.selectbox("üè∑Ô∏è Filtrer par cat√©gorie", ["Aucun"] + text_cols)
            if text_col != "Aucun":
                unique_vals = df_filtered[text_col].dropna().astype(str).unique()
                if len(unique_vals) > 0 and len(unique_vals) <= 100:
                    selected_vals = st.multiselect(
                        f"Valeurs de {text_col}",
                        options=sorted(unique_vals),
                        default=list(unique_vals[:10])
                    )
                    if selected_vals:
                        df_filtered = df_filtered[df_filtered[text_col].astype(str).isin(selected_vals)]

        # Filtre num√©rique
        if numeric_cols:
            num_col = st.selectbox("üî¢ Filtrer par valeur", ["Aucun"] + numeric_cols)
            if num_col != "Aucun":
                min_val = float(df_filtered[num_col].min())
                max_val = float(df_filtered[num_col].max())
                if min_val < max_val:
                    val_range = st.slider(
                        f"Plage de {num_col}",
                        min_val, max_val, (min_val, max_val)
                    )
                    df_filtered = df_filtered[
                        (df_filtered[num_col] >= val_range[0]) &
                        (df_filtered[num_col] <= val_range[1])
                    ]

    return df_filtered

# ========================================
# AFFICHAGE PRINCIPAL
# ========================================

if df is None:
    st.info("üëà **Importez vos fichiers dans la barre lat√©rale pour commencer**")
    st.markdown("""
    ### üéØ Fonctionnalit√©s :
    - ‚úÖ Import multi-fichiers (CSV + XLSX)
    - ‚úÖ Fusion automatique des donn√©es
    - ‚úÖ Filtres intuitifs
    - ‚úÖ Visualisations interactives (camemberts, barres, courbes, etc.)
    - ‚úÖ Export PDF du rapport
    """)
else:
    # Traitement des donn√©es
    df, numeric_cols, date_cols, text_cols = detect_column_types(df)
    # Ajout des colonnes d√©riv√©es pour assurer le fonctionnement des graphes
    df, numeric_cols, date_cols, text_cols = add_derived_features(df, numeric_cols, date_cols, text_cols)

    # KPIs en haut
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìä Lignes totales", f"{len(df):,}")
    with col2:
        st.metric("üìã Colonnes", f"{len(df.columns)-1}")
    with col3:
        missing = (df.isna().sum().sum() / (len(df) * len(df.columns)) * 100)
        st.metric("‚ö†Ô∏è Donn√©es manquantes", f"{missing:.1f}%")
    with col4:
        if '_fichier_source' in df.columns:
            st.metric("üìÅ Fichiers", df['_fichier_source'].nunique())

    # Application des filtres
    df_filtered = apply_filters(df, numeric_cols, date_cols, text_cols)

    if len(df_filtered) < len(df):
        st.info(f"üîç **{len(df_filtered):,}** lignes affich√©es sur **{len(df):,}** (filtre actif)")

    # Aper√ßu des donn√©es
    st.subheader("üìã Aper√ßu des donn√©es")
    st.dataframe(df_filtered.head(100), use_container_width=True)

    # Boutons de t√©l√©chargement
    col_dl1, col_dl2 = st.columns(2)
    with col_dl1:
        csv_data = df_filtered.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• T√©l√©charger CSV",
            csv_data,
            "donnees.csv",
            "text/csv"
        )

    # ========================================
    # SECTION 4 : VISUALISATIONS
    # ========================================

    st.markdown("---")
    st.subheader("üìà Visualisations")

    viz_tabs = st.tabs([
        "ü•ß Camembert",
        "üìä Barres",
        "üìà Courbes",
        "üå≥ TreeMap",
        "‚òÄÔ∏è Sunburst",
        "üî• Heatmap",
        "üíπ Nuage de points"
    ])

    # TAB 1: CAMEMBERT
    with viz_tabs[0]:
        st.markdown("### ü•ß R√©partition par cat√©gorie")
        if text_cols:
            col_pie1, col_pie2 = st.columns(2)
            with col_pie1:
                pie_col = st.selectbox("Choisir la cat√©gorie", text_cols, key="pie_cat")
            with col_pie2:
                top_n = st.slider("Nombre de cat√©gories", 5, 20, 10, key="pie_top")

            # Calcul des donn√©es
            pie_data = (
                df_filtered[pie_col]
                .dropna()
                .astype(str)
                .value_counts()
                .head(top_n)
                .reset_index()
            )
            pie_data.columns = ['Cat√©gorie', 'Valeur']

            if len(pie_data) > 0:
                # Graphique am√©lior√©
                fig = px.pie(
                    pie_data,
                    names='Cat√©gorie',
                    values='Valeur',
                    title=f"Top {top_n} - {pie_col}",
                    hole=0.3,  # Donut
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig.update_traces(
                    textposition='outside',
                    textinfo='percent+label',
                    marker=dict(line=dict(color='white', width=2))
                )
                fig.update_layout(
                    showlegend=True,
                    height=500,
                    legend=dict(orientation="h", yanchor="bottom", y=-0.2)
                )
                st.plotly_chart(fig, use_container_width=True)

                # Tableau de donn√©es
                with st.expander("üìä Voir les chiffres d√©taill√©s"):
                    st.dataframe(pie_data, use_container_width=True)
            else:
                st.warning("Aucune donn√©e √† afficher")
        else:
            st.info("Aucune colonne cat√©gorielle d√©tect√©e")

    # TAB 2: BARRES
    with viz_tabs[1]:
        st.markdown("### üìä Graphique en barres")
        if text_cols and numeric_cols:
            col_bar1, col_bar2, col_bar3 = st.columns(3)
            with col_bar1:
                bar_cat = st.selectbox("Cat√©gorie (X)", text_cols, key="bar_cat")
            with col_bar2:
                bar_val = st.selectbox("Valeur (Y)", numeric_cols, key="bar_val")
            with col_bar3:
                bar_top = st.slider("Top N", 5, 30, 15, key="bar_top")

            # Agr√©gation
            bar_data = (
                df_filtered.groupby(bar_cat)[bar_val]
                .sum()
                .sort_values(ascending=False)
                .head(bar_top)
                .reset_index()
            )

            if len(bar_data) > 0:
                fig = px.bar(
                    bar_data,
                    x=bar_cat,
                    y=bar_val,
                    title=f"{bar_val} par {bar_cat}",
                    color=bar_val,
                    color_continuous_scale='Blues'
                )
                fig.update_layout(xaxis_tickangle=-45, height=500)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Aucune donn√©e √† afficher")
        else:
            st.info("Il faut au moins une colonne cat√©gorielle et une colonne num√©rique")

    # TAB 3: COURBES
    with viz_tabs[2]:
        st.markdown("### üìà √âvolution temporelle")
        if date_cols and numeric_cols:
            col_line1, col_line2, col_line3 = st.columns(3)
            with col_line1:
                line_date = st.selectbox("Date", date_cols, key="line_date")
            with col_line2:
                line_val = st.selectbox("Valeur", numeric_cols, key="line_val")
            with col_line3:
                line_gran = st.selectbox("Granularit√©", ["Jour", "Semaine", "Mois"], index=0, key="line_gran")

            # Agr√©gation selon la granularit√©
            df_line = df_filtered.dropna(subset=[line_date]).copy()
            dts = pd.to_datetime(df_line[line_date])
            if line_gran == "Jour":
                df_line['_bucket'] = dts.dt.date
            elif line_gran == "Semaine":
                # Lundi comme d√©but de semaine
                df_line['_bucket'] = (dts - pd.to_timedelta(dts.dt.weekday, unit='D')).dt.date
            else:  # Mois
                df_line['_bucket'] = dts.dt.to_period('M').dt.to_timestamp().dt.date

            line_data = df_line.groupby('_bucket')[line_val].sum().reset_index().sort_values('_bucket')

            if len(line_data) > 0:
                fig = px.line(
                    line_data,
                    x='_bucket',
                    y=line_val,
                    title=f"√âvolution de {line_val} par {line_gran}",
                    markers=True
                )
                fig.update_layout(hovermode='x unified', height=500, xaxis_title=line_gran)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Aucune donn√©e √† afficher")
        else:
            st.info("Il faut au moins une colonne de date et une colonne num√©rique")

    # TAB 4: TREEMAP
    with viz_tabs[3]:
        st.markdown("### üå≥ TreeMap (vision hi√©rarchique)")
        if text_cols and numeric_cols:
            col_tree1, col_tree2 = st.columns(2)
            with col_tree1:
                tree_cat = st.selectbox("Cat√©gorie", text_cols, key="tree_cat")
            with col_tree2:
                tree_val = st.selectbox("Valeur", numeric_cols, key="tree_val")

            tree_data = (
                df_filtered.groupby(tree_cat)[tree_val]
                .sum()
                .sort_values(ascending=False)
                .head(20)
                .reset_index()
            )

            if len(tree_data) > 0:
                fig = px.treemap(
                    tree_data,
                    path=[tree_cat],
                    values=tree_val,
                    title=f"{tree_val} par {tree_cat}",
                    color=tree_val,
                    color_continuous_scale='RdYlGn'
                )
                fig.update_layout(height=600)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Aucune donn√©e √† afficher")
        else:
            st.info("Il faut au moins une colonne cat√©gorielle et une colonne num√©rique")

    # TAB 5: SUNBURST
    with viz_tabs[4]:
        st.markdown("### ‚òÄÔ∏è Sunburst (2 niveaux)")
        if len(text_cols) >= 2 and numeric_cols:
            col_sun1, col_sun2, col_sun3 = st.columns(3)
            with col_sun1:
                sun_cat1 = st.selectbox("Niveau 1", text_cols, key="sun_1")
            with col_sun2:
                sun_cat2 = st.selectbox("Niveau 2", [c for c in text_cols if c != sun_cat1], key="sun_2")
            with col_sun3:
                sun_val = st.selectbox("Valeur", numeric_cols, key="sun_val")

            sun_data = df_filtered.groupby([sun_cat1, sun_cat2])[sun_val].sum().reset_index()

            if len(sun_data) > 0:
                fig = px.sunburst(
                    sun_data,
                    path=[sun_cat1, sun_cat2],
                    values=sun_val,
                    title=f"{sun_val} : {sun_cat1} ‚Üí {sun_cat2}",
                    color=sun_val,
                    color_continuous_scale='Viridis'
                )
                fig.update_layout(height=600)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Aucune donn√©e √† afficher")
        else:
            st.info("Il faut au moins 2 colonnes cat√©gorielle et 1 colonne num√©rique")

    # TAB 6: HEATMAP
    with viz_tabs[5]:
        st.markdown("### üî• Heatmap (corr√©lation)")
        if len(text_cols) >= 2 and numeric_cols:
            col_heat1, col_heat2, col_heat3 = st.columns(3)
            with col_heat1:
                heat_x = st.selectbox("Axe X", text_cols, key="heat_x")
            with col_heat2:
                heat_y = st.selectbox("Axe Y", [c for c in text_cols if c != heat_x], key="heat_y")
            with col_heat3:
                heat_z = st.selectbox("Valeur", numeric_cols, key="heat_z")

            pivot = df_filtered.pivot_table(
                index=heat_y,
                columns=heat_x,
                values=heat_z,
                aggfunc='sum',
                fill_value=0
            )

            # Limiter pour lisibilit√©
            if pivot.shape[0] > 15:
                pivot = pivot.iloc[:15]
            if pivot.shape[1] > 15:
                pivot = pivot.iloc[:, :15]

            if pivot.size > 0:
                fig = go.Figure(data=go.Heatmap(
                    z=pivot.values,
                    x=pivot.columns,
                    y=pivot.index,
                    colorscale='YlOrRd'
                ))
                fig.update_layout(
                    title=f"{heat_z} : {heat_y} vs {heat_x}",
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Aucune donn√©e √† afficher")
        else:
            st.info("Il faut au moins 2 colonnes cat√©gorielle et 1 colonne num√©rique")

    # TAB 7: SCATTER
    with viz_tabs[6]:
        st.markdown("### üíπ Nuage de points")
        if len(numeric_cols) >= 2:
            col_scat1, col_scat2, col_scat3 = st.columns(3)
            with col_scat1:
                scat_x = st.selectbox("X", numeric_cols, key="scat_x")
            with col_scat2:
                scat_y = st.selectbox("Y", [c for c in numeric_cols if c != scat_x], key="scat_y")
            with col_scat3:
                scat_color = st.selectbox("Couleur", ["Aucune"] + text_cols, key="scat_color")

            # √âchantillonnage pour performance
            sample_size = min(2000, len(df_filtered))
            df_sample = df_filtered.sample(sample_size) if len(df_filtered) > sample_size else df_filtered

            fig = px.scatter(
                df_sample,
                x=scat_x,
                y=scat_y,
                color=None if scat_color == "Aucune" else scat_color,
                title=f"{scat_y} vs {scat_x}",
                opacity=0.6
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Il faut au moins 2 colonnes num√©riques")

    # ========================================
    # SECTION 5 : EXPORT PDF
    # ========================================

    st.markdown("---")
    st.subheader("üìÑ Export du rapport")

    if st.button("üéØ G√©n√©rer le rapport PDF", type="primary"):
        if not HAS_REPORTLAB:
            st.error("‚ùå La biblioth√®que reportlab n'est pas install√©e. Ex√©cutez : pip install reportlab")
        else:
            try:
                pdf_buffer = BytesIO()
                doc = SimpleDocTemplate(pdf_buffer, pagesize=A4)
                story = []
                styles = getSampleStyleSheet()

                # Titre
                title_style = ParagraphStyle(
                    'CustomTitle',
                    parent=styles['Heading1'],
                    fontSize=24,
                    textColor=colors.HexColor('#1f77b4'),
                    spaceAfter=30
                )
                story.append(Paragraph("üìä Rapport d'Analyse Marketing", title_style))
                story.append(Paragraph(f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}", styles['Normal']))
                story.append(Spacer(1, 0.3*inch))

                # R√©sum√© des donn√©es
                story.append(Paragraph("üìã R√©sum√© des donn√©es", styles['Heading2']))
                # Pr√©-calcul des valeurs pour √©viter des f-strings imbriqu√©es
                nb_lignes = f"{len(df_filtered):,}"
                nb_colonnes = f"{len(df_filtered.columns)}"
                fichiers_sources = (
                    df_filtered['_fichier_source'].nunique() if '_fichier_source' in df_filtered.columns else 'N/A'
                )
                periode_analyse = datetime.now().strftime('%B %Y')

                summary_data = [
                    ['M√©trique', 'Valeur'],
                    ['Nombre de lignes', nb_lignes],
                    ['Nombre de colonnes', nb_colonnes],
                    ['Fichiers sources', str(fichiers_sources)],
                    ['P√©riode d\'analyse', periode_analyse]
                ]

                summary_table = Table(summary_data, colWidths=[3*inch, 3*inch])
                summary_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 12),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                    ('GRID', (0, 0), (-1, -1), 1, colors.black)
                ]))
                story.append(summary_table)
                story.append(Spacer(1, 0.3*inch))

                # Top cat√©gories
                if text_cols:
                    story.append(PageBreak())
                    story.append(Paragraph(f"üèÜ Top cat√©gories - {text_cols[0]}", styles['Heading2']))
                    top_cats = df_filtered[text_cols[0]].value_counts().head(10).reset_index()
                    top_cats.columns = ['Cat√©gorie', 'Nombre']

                    cat_data = [['Cat√©gorie', 'Nombre']]
                    for _, row in top_cats.iterrows():
                        cat_data.append([str(row['Cat√©gorie'])[:50], f"{row['Nombre']:,}"])

                    cat_table = Table(cat_data, colWidths=[4*inch, 2*inch])
                    cat_table.setStyle(TableStyle([
                        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f77b4')),
                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                        ('FONTSIZE', (0, 0), (-1, 0), 11),
                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                        ('BACKGROUND', (0, 1), (-1, -1), colors.lightblue),
                        ('GRID', (0, 0), (-1, -1), 1, colors.black),
                        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.lightgrey])
                    ]))
                    story.append(cat_table)

                # Statistiques num√©riques
                if numeric_cols:
                    story.append(PageBreak())
                    story.append(Paragraph("üìä Statistiques des valeurs num√©riques", styles['Heading2']))

                    stats_data = [['Colonne', 'Minimum', 'Maximum', 'Moyenne', 'Total']]
                    for col in numeric_cols[:5]:  # Limiter √† 5 colonnes
                        stats_data.append([
                            col[:30],
                            f"{df_filtered[col].min():.2f}",
                            f"{df_filtered[col].max():.2f}",
                            f"{df_filtered[col].mean():.2f}",
                            f"{df_filtered[col].sum():.2f}"
                        ])

                    stats_table = Table(stats_data, colWidths=[2*inch, 1*inch, 1*inch, 1*inch, 1.5*inch])
                    stats_table.setStyle(TableStyle([
                        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2ca02c')),
                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                        ('FONTSIZE', (0, 0), (-1, -1), 9),
                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                        ('BACKGROUND', (0, 1), (-1, -1), colors.lightgreen),
                        ('GRID', (0, 0), (-1, -1), 1, colors.black)
                    ]))
                    story.append(stats_table)

                # G√©n√©rer le PDF
                doc.build(story)
                pdf_buffer.seek(0)

                st.success("‚úÖ Rapport g√©n√©r√© avec succ√®s !")
                st.download_button(
                    "üì• T√©l√©charger le rapport PDF",
                    pdf_buffer,
                    f"rapport_marketing_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    "application/pdf"
                )

            except Exception as e:
                st.error(f"‚ùå Erreur lors de la g√©n√©ration du PDF : {str(e)}")

st.markdown("---")
st.caption("üí° Astuce : Les filtres sont dans la barre lat√©rale. Les graphiques s'adaptent automatiquement √† vos donn√©es !")
